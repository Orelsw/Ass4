train_query_clean<-DocumentTermMatrix(cleanText(train_Data$query), control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
rm(list = ls(all = TRUE))
rm(list = ls(all = TRUE))
library(stringdist)
library(tm)
library(readr)
library(rpart)
library(party)
library(caret)
library(randomForest)
library(SnowballC)
library(slam)
library(topicmodels)
library(lsa)
cleanText <- function(col){
train_product_title_source <- VectorSource(col)
corpus<- Corpus(train_product_title_source)
corpus<-tm_map(corpus,removePunctuation)
corpus<-tm_map(corpus,tolower)
corpus<-tm_map(corpus,removeNumbers)
corpus<-tm_map(corpus,removeWords,stopwords("english"))
corpus<-tm_map(corpus,stripWhitespace)
for(j in seq(corpus))
{
corpus[[j]] <- gsub("/", " ", corpus[[j]])
corpus[[j]] <- gsub("@", " ", corpus[[j]])
corpus[[j]] <- gsub("\\|", " ", corpus[[j]])
corpus[[j]] <- stemSentence(corpus[[j]],"english")
}
corpus <- tm_map(corpus, PlainTextDocument)
return(corpus)
}
stemSentence<-function(x, language){
x<- strsplit(x, "[[:blank:]]")[[1]]
x<- wordStem(x, language)
paste(x, collapse=" ")
}
calculateLength<-function(col){
length<-c()
matrix<-as.matrix(col)
for(i in seq(col)){
temp<-strsplit(matrix[[i]],split=" ")
length[i]<-
}
}
unzip("train.csv.zip")
train <- read_csv("train.csv")
unzip("test.csv.zip")
test <- read_csv("test.csv")
# Summarize information about a list of sentance in train.
train_Data <- read.csv("train.csv",stringsAsFactors = FALSE)
test_Data <- read.csv("test.csv",stringsAsFactors = FALSE)
train_query_clean<-DocumentTermMatrix(cleanText(train_Data$query), control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
train_product_title_clean<-cleanText(train_Data$product_title,Terms(train_query_clean))
train_product_description_clean<-cleanText(train_Data$product_description,Terms(train_query_clean))
test_query_clean<-cleanText(test_Data$query,NULL)
test_product_title_clean<-cleanText(test_Data$product_title,Terms(test_query_clean))
test_product_description_clean<-cleanText(test_Data$product_description,Terms(test_query_clean))
train_query_clean<-DocumentTermMatrix(cleanText(train_Data$query), control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
train_product_title_clean<-cleanText(train_Data$product_title,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf)))
train_product_description_clean<-cleanText(train_Data$product_description,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf)))
test_query_clean<-cleanText(test_Data$query, control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
test_product_title_clean<-cleanText(test_Data$product_title,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(test_query_clean),
wordLengths=c(2,Inf)))
test_product_description_clean<-cleanText(test_Data$product_description,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(test_query_clean),
wordLengths=c(2,Inf)))
train_query_clean<-DocumentTermMatrix(cleanText(train_Data$query), control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
train_product_title_clean<-cleanText(train_Data$product_title,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf)))
train_query_clean<-DocumentTermMatrix(cleanText(train_Data$query), control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
train_product_title_clean<-DocumentTermMatrix(cleanText(train_Data$product_title,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf))))
train_product_description_clean<-DocumentTermMatrix(cleanText(train_Data$product_description,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf))))
test_query_clean<-DocumentTermMatrix(cleanText(test_Data$query, control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf))))
test_product_title_clean<-DocumentTermMatrix(cleanText(test_Data$product_title,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(test_query_clean),
wordLengths=c(2,Inf))))
test_product_description_clean<-DocumentTermMatrix(cleanText(test_Data$product_description,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(test_query_clean),
wordLengths=c(2,Inf))))
train_query_clean<-DocumentTermMatrix(cleanText(train_Data$query), control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
train_product_title_clean<-DocumentTermMatrix(cleanText(train_Data$product_title),control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf)))
train_product_description_clean<-DocumentTermMatrix(cleanText(train_Data$product_description),control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf)))
test_query_clean<-DocumentTermMatrix(cleanText(test_Data$query), control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
test_product_title_clean<-DocumentTermMatrix(cleanText(test_Data$product_title),control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(test_query_clean),
wordLengths=c(2,Inf)))
test_product_description_clean<-DocumentTermMatrix(cleanText(test_Data$product_description),control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(test_query_clean),
wordLengths=c(2,Inf)))
train_query_product_title<-as.matrix(train_query_clean)*as.matrix(train_product_title_clean)
train_query_product_title_simi<-rowSums(train_query_product_title)
train_query_product_description<-as.matrix(train_query_clean)*as.matrix(train_product_description_clean)
train_query_product_description_simi<-rowSums(train_query_product_title)
test_query_product_title<-as.matrix(test_query_clean)*as.matrix(test_product_title_clean)
test_query_product_title_simi<-rowSums(test_query_product_title)
test_query_product_description<-as.matrix(test_query_clean)*as.matrix(test_product_description_clean)
test_query_product_description_simi<-rowSums(test_query_product_title)
View(train_query_product_title)
train_q<-cleanText(train_Data$query)
test_q<-cleanText(test_Data$query)
train_q
as.vector(train_q)
as.matrix(train_q)
train_q_DF<-data.frame(text=unlist(sapply(train_q, `[`, "content")),
stringsAsFactors=F)
train_q_DF
train_q_DF[1]
train_q_DF[[1]
]
train_q_DF[[1]][1]
calculateLength<-function(col){
colLength<-c()
for(i in seq(col)){
temp<-strsplit(colLength[[1]][i],split=" ")
colLength[i]<-length(temp)
}
return(colLength)
}
calculateLength(train_q_DF)
train_q_DF
strsplit(train_q_DF," ")
strsplit(train_q_DF,split=" ")
strsplit(train_q_DF[[1]],split=" ")
calculateLength<-function(col){
colLength<-c()
temp<-strsplit(colLength[[1]],split=" ")
for(i in seq(temp)){
colLength[i]<-length(temp[[1]])
}
return(colLength)
}
calculateLength<-function(col){
colLength<-c()
temp<-strsplit(colLength[[1]],split=" ")
for(i in seq(temp)){
colLength[i]<-length(temp[[1]][i])
}
return(colLength)
}
query_length<-calculateLength(train_q_DF)
calculateLength<-function(col){
colLength<-c()
temp<-strsplit(col[[1]],split=" ")
for(i in seq(temp)){
colLength[i]<-length(temp[[1]][i])
}
return(colLength)
}
query_length<-calculateLength(train_q_DF)
query_length
calculateLength<-function(col){
colLength<-c()
temp<-strsplit(col[[1]],split=" ")
for(i in seq(temp)){
print(temp[[1]][i])
colLength[i]<-length(temp[[1]][i])
}
return(colLength)
}
query_length<-calculateLength(train_q_DF)
temp<-strsplit(train_q_DF[[1]],split=" ")
temp
temp[1]
temp[2]
calculateLength<-function(col){
colLength<-c()
temp<-strsplit(col[[1]],split=" ")
for(i in seq(temp)){
colLength[i]<-length(temp[i])
}
return(colLength)
}
query_length<-calculateLength(train_q_DF)
query_length
temp[2]
length(temp[2])
size(temp[2])
temp[2]
temp[2][[1]]
calculateLength<-function(col){
colLength<-c()
temp<-strsplit(col[[1]],split=" ")
for(i in seq(temp)){
colLength[i]<-length(temp[i][[1]])
}
return(colLength)
}
query_length<-calculateLength(train_q_DF)
query_length
test_q_DF<-data.frame(text=unlist(sapply(test_q, `[`, "content")),
stringsAsFactors=F)
# Chunk 1
rm(list = ls(all = TRUE))
# Chunk 2
library(stringdist)
library(tm)
library(readr)
library(rpart)
library(party)
library(caret)
library(randomForest)
library(SnowballC)
library(slam)
library(topicmodels)
library(lsa)
# Chunk 3
cleanText <- function(col){
train_product_title_source <- VectorSource(col)
corpus<- Corpus(train_product_title_source)
corpus<-tm_map(corpus,removePunctuation)
corpus<-tm_map(corpus,tolower)
corpus<-tm_map(corpus,removeNumbers)
corpus<-tm_map(corpus,removeWords,stopwords("english"))
corpus<-tm_map(corpus,stripWhitespace)
for(j in seq(corpus))
{
corpus[[j]] <- gsub("/", " ", corpus[[j]])
corpus[[j]] <- gsub("@", " ", corpus[[j]])
corpus[[j]] <- gsub("\\|", " ", corpus[[j]])
corpus[[j]] <- stemSentence(corpus[[j]],"english")
}
corpus <- tm_map(corpus, PlainTextDocument)
return(corpus)
}
# Chunk 4
stemSentence<-function(x, language){
x<- strsplit(x, "[[:blank:]]")[[1]]
x<- wordStem(x, language)
paste(x, collapse=" ")
}
# Chunk 5
calculateLength<-function(col){
colLength<-c()
temp<-strsplit(col[[1]],split=" ")
for(i in seq(temp)){
colLength[i]<-length(temp[i][[1]])
}
return(colLength)
}
# Chunk 6
unzip("train.csv.zip")
train <- read_csv("train.csv")
unzip("test.csv.zip")
test <- read_csv("test.csv")
# Summarize information about a list of sentance in train.
train_Data <- read.csv("train.csv",stringsAsFactors = FALSE)
test_Data <- read.csv("test.csv",stringsAsFactors = FALSE)
# Chunk 7
train_q<-cleanText(train_Data$query)
train_q_DF<-data.frame(text=unlist(sapply(train_q, `[`, "content")),
stringsAsFactors=F)
train_query_clean<-DocumentTermMatrix(train_q, control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
train_product_title_clean<-DocumentTermMatrix(cleanText(train_Data$product_title),control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf)))
train_product_description_clean<-DocumentTermMatrix(cleanText(train_Data$product_description),control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(train_query_clean),
wordLengths=c(2,Inf)))
test_q<-cleanText(test_Data$query)
test_q_DF<-data.frame(text=unlist(sapply(test_q, `[`, "content")),
stringsAsFactors=F)
test_query_clean<-DocumentTermMatrix(test_q, control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
test_product_title_clean<-DocumentTermMatrix(cleanText(test_Data$product_title),control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(test_query_clean),
wordLengths=c(2,Inf)))
test_product_description_clean<-DocumentTermMatrix(cleanText(test_Data$product_description),control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(test_query_clean),
wordLengths=c(2,Inf)))
# Chunk 8
train_query_product_title<-as.matrix(train_query_clean)*as.matrix(train_product_title_clean)
train_query_product_title_simi<-rowSums(train_query_product_title)
train_query_product_description<-as.matrix(train_query_clean)*as.matrix(train_product_description_clean)
train_query_product_description_simi<-rowSums(train_query_product_title)
test_query_product_title<-as.matrix(test_query_clean)*as.matrix(test_product_title_clean)
test_query_product_title_simi<-rowSums(test_query_product_title)
test_query_product_description<-as.matrix(test_query_clean)*as.matrix(test_product_description_clean)
test_query_product_description_simi<-rowSums(test_query_product_title)
train_query_product_title_simi[1]
train_query_product_title_simi[2]
train_query_product_title_simi[4]
train_query_product_title_simi
View(train_query_product_title)
train$median_relevance <- factor(train$median_relevance)
train_query_length<-calculateLength(train_q_DF)
test_query_length<-calculateLength(test_q_DF)
for(j in seq(train$id))
{
if(train$product_description[[j]]==""){
train$score[[j]]<-query_product_title_simi[j]/train_query_length[j]
} else{
train$score[[j]]<-(query_product_title_simi[[j]]+
query_product_description_simi[[j]])/(2*train_query_length[j])
}
}
for(j in seq(train$id))
{
if(train$product_description[[j]]==""){
train$score[[j]]<-train_query_product_title_simi[j]/train_query_length[j]
} else{
train$score[[j]]<-(train_query_product_title_simi[[j]]+
train_query_product_description_simi[[j]])/(2*train_query_length[j])
}
}
View(train)
for(j in seq(train$id))
{
if(train$product_description[[j]]==""){
train$score[[j]]<-train_query_product_title_simi[j]/train_query_length[j]
}
else{
train$score[[j]]<-(train_query_product_title_simi[j]+
train_query_product_description_simi[j])/(2*train_query_length[j])
}
}
train$median_relevance <- factor(train$median_relevance)
train_query_length<-calculateLength(train_q_DF)
test_query_length<-calculateLength(test_q_DF)
for(j in seq(train$id))
{
if(train$product_description[[j]]==""){
train$score[[j]]<-train_query_product_title_simi[j]/train_query_length[j]
}
else{
train$score[[j]]<-(train_query_product_title_simi[j]+
train_query_product_description_simi[j])/(2*train_query_length[j])
}
}
for(j in seq(test$id))
{
if(test$product_description[[j]]==""){
test$score[[j]]<-test_query_product_title_simi[j]/test_query_length[j]
}
else{
test$score[[j]]<-(test_query_product_title_simi[j]+
test_query_product_description_simi[j])/(2*test_query_length[j])
}
}
View(test)
model <- randomForest(median_relevance ~ score, data=train, ntree=3)
results <- predict(model, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
model <- randomForest(median_relevance ~ score, data=train, ntree=1)
results <- predict(model, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
model <- randomForest(median_relevance ~ score, data=train, ntree=2)
results <- predict(model, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
model <- randomForest(median_relevance ~ score, data=train, ntree=10)
results <- predict(model, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
model <- randomForest(median_relevance ~ score, data=train, ntree=30)
results <- predict(model, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
model <- randomForest(median_relevance ~ score, data=train, ntree=100)
results <- predict(model, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
model2 <- train(median_relevance ~ score, data = train,
method = "rpart",
trControl = trainControl(classProbs = F))
setwd("~/Google Drive/DataScientist/Ass4")
library(stringdist)
library(tm)
library(readr)
library(rpart)
library(party)
library(caret)
library(randomForest)
library(SnowballC)
library(slam)
library(topicmodels)
library(stringdist)
library(tm)
library(readr)
library(rpart)
library(party)
library(caret)
library(randomForest)
library(SnowballC)
library(slam)
library(topicmodels)
cleanText <- function(col){
train_product_title_source <- VectorSource(col)
corpus<- Corpus(train_product_title_source)
corpus<-tm_map(corpus,removePunctuation)
corpus<-tm_map(corpus,tolower)
corpus<-tm_map(corpus,removeNumbers)
corpus<-tm_map(corpus,removeWords,stopwords("english"))
corpus<-tm_map(corpus,stripWhitespace)
for(j in seq(corpus))
{
corpus[[j]] <- gsub("/", " ", corpus[[j]])
corpus[[j]] <- gsub("@", " ", corpus[[j]])
corpus[[j]] <- gsub("\\|", " ", corpus[[j]])
corpus[[j]] <- stemSentence(corpus[[j]],"english")
}
corpus <- tm_map(corpus, PlainTextDocument)
return(corpus)
}
stemSentence<-function(x, language){
x<- strsplit(x, "[[:blank:]]")[[1]]
x<- wordStem(x, language)
paste(x, collapse=" ")
}
calculateLength<-function(col){
colLength<-c()
temp<-strsplit(col[[1]],split=" ")
for(i in seq(temp)){
colLength[i]<-length(temp[i][[1]])
}
return(colLength)
}
claculateScore<-function(fileName){
# Loading the data
unzip(paste(fileName, ".csv.zip", sep = ""))
sourceFile <- read_csv(paste(fileName, ".csv", sep = ""))
File_Data  <- read.csv(paste(fileName, ".csv", sep = ""),stringsAsFactors = FALSE)
# Preprocessing - Clean Text
querys_Clean      <- cleanText(File_Data$query)
title_Clean       <- cleanText(File_Data$product_title)
description_Clean <- cleanText(File_Data$product_description)
# Create DTM for each colomn base on dictionary=Terms(query_DTM)
query_DTM       <- DocumentTermMatrix(querys_Clean, control=list(bounds = list(local = c(0, Inf)),
dictionary=NULL,
wordLengths=c(2,Inf)))
title_DTM       <- DocumentTermMatrix(title_Clean,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(query_DTM),
wordLengths=c(2,Inf)))
description_DTM <- DocumentTermMatrix(description_Clean,control=list(bounds = list(local = c(0, Inf)),
dictionary=Terms(query_DTM),
wordLengths=c(2,Inf)))
# Caculate Similarity between: query<->title & query<->description
query_title            <- as.matrix(query_DTM)*as.matrix(title_DTM)
query_title_simi       <- rowSums(query_title)
query_description      <- as.matrix(query_DTM)*as.matrix(description_DTM)
query_description_simi <- rowSums(query_description)
# Calculate Score
query_DF<-data.frame(text=unlist(sapply(querys_Clean, `[`, "content")),
stringsAsFactors=F)
query_length<-calculateLength(query_DF)
for(j in seq(sourceFile$id))
{
if(sourceFile$product_description[[j]]==""){
sourceFile$score[[j]] <- query_title_simi[j]/query_length[j]
}
else{
sourceFile$score[[j]] <- (query_title_simi[j]+
query_description_simi[j])/(2*query_length[j])
}
}
return(sourceFile)
}
train <- claculateScore("train")
test <- claculateScore("test")
train$median_relevance <- factor(train$median_relevance)
model1 <- randomForest(median_relevance ~ score, data=train, ntree=3)
model2 <- train(median_relevance ~ score, data = train,
method = "rpart",
trControl = trainControl(classProbs = F))
results <- predict(model2, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
results <- predict(model1, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
train$median_relevance <- factor(train$median_relevance)
model1 <- randomForest(median_relevance ~ score, data=train, ntree=100)
results <- predict(model1, newdata = test)
Newsubmission = data.frame(id=test$id, prediction = results)
write.csv(Newsubmission,"model.csv",row.names=F)
